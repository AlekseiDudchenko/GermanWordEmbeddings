{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with word2vec\n",
    "##### See [training.py](https://github.com/devmount/GermanWordEmbeddings/blob/master/training.py) from [GermanWordEmbeddings](https://devmount.github.io/GermanWordEmbeddings/)\n",
    "\n",
    "The following code gives an example of how to train a language model with the training script. You need [gensim](https://radimrehurek.com/gensim/install.html) for this script to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General usage\n",
    "The usage of the script can be seen with the default `-h` or `--help` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: training.py [-h] [-s SIZE] [-w WINDOW] [-m MINCOUNT] [-c WORKERS] [-g SG] [-i HS] [-n NEGATIVE] [-o CBOWMEAN]\n",
      "                   corpora target\n",
      "\n",
      "Script for training word vector models using public corpora\n",
      "\n",
      "positional arguments:\n",
      "  corpora               source folder with preprocessed corpora (one sentence plain text per line in each file)\n",
      "  target                target file name to store model in\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -s SIZE, --size SIZE  dimension of word vectors\n",
      "  -w WINDOW, --window WINDOW\n",
      "                        size of the sliding window\n",
      "  -m MINCOUNT, --mincount MINCOUNT\n",
      "                        minimum number of occurences of a word to be considered\n",
      "  -c WORKERS, --workers WORKERS\n",
      "                        number of worker threads to train the model\n",
      "  -g SG, --sg SG        training algorithm: Skip-Gram (1), otherwise CBOW (0)\n",
      "  -i HS, --hs HS        use of hierachical sampling for training\n",
      "  -n NEGATIVE, --negative NEGATIVE\n",
      "                        use of negative sampling for training (usually between 5-20)\n",
      "  -o CBOWMEAN, --cbowmean CBOWMEAN\n",
      "                        for CBOW training algorithm: use sum (0) or mean (1) to merge context vectors\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python training.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training example\n",
    "The example corpus from the preprocessing section is now used to train a small language model with vector size of 300, window size of 5, negative sampling with 10 samples and minimum word occurences of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"training.py\", line 29, in <module>\n",
      "    logging.basicConfig(stream=sys.stdout, format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "NameError: name 'sys' is not defined\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python training.py corpus/ my.model -s 300 -w 5 -n 10 -m 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model can be used now for evaluation and visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
